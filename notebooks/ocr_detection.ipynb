{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OS, setting OS environment here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALert! This cuda_launch_blocking is only for debugging purposes. It is not recommended to use it in production.\n",
    "# This will SLOW DOWN the training process.\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from collections import defaultdict\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import time\n",
    "from PIL import Image\n",
    "import os\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Wandb to record the experiment process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"OCR_extract.ipynb\"\n",
    "\n",
    "wandb.init(project=\"OCR_Recognition\", name=\"ResNet18_LSTM_1\")\n",
    "\n",
    "wandb.config.update({\"starting_learning_rate\": 0.001, \"epochs\": 200, \"batch_size\": 32})\n",
    "wandb.config.update({\"cnn_backend\": \"ResNet50\", \"dataset\": \"OCR\", \"optimizer\": \"AdamW\", \"scheduler\": \"ReduceLROnPlateau\"})\n",
    "wandb.config.update({\"loss_function\": \"CTCLoss\", \"pretrained\": True, \"pretrained_weights\": \"IMAGENET1K_V2\"})\n",
    "wandb.config.update({\"lr_scheduler\": \"ReduceLROnPlateau\", \"lr_patience\": 5, \"lr_factor\": 0.1, \"lr_min\": 1e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the configuration class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    anonymous = 'allow'\n",
    "    backend_model = 'resnet18'\n",
    "    notes = \"This is a self-developed model with pretrained resnet18 as backbone and LSTM as decoder.\"\n",
    "    save_code = True # save code in wandb\n",
    "    image_size = [500, 1200]\n",
    "    group = None\n",
    "    force = True # The user msu have logged into the wandb account\n",
    "    train_batch_size = 32\n",
    "    test_batch_size = 32\n",
    "    epochs = 200\n",
    "    optimizer = 'AdamW'\n",
    "    scheduler = 'CosineAnnealingwithWarmRestarts'\n",
    "    T_0 = 20\n",
    "    T_mult = 1\n",
    "    eta_min = 0.001\n",
    "    last_epoch = -1\n",
    "    verbose = False\n",
    "    loss_function = 'CrossEntropyLoss' # 'CTCLoss' would be tested after the first 200 epochs\n",
    "    pretrained = True\n",
    "    pretrained_resnet18_weights = 'IMAGENET1K_V1'\n",
    "    pretrained_resnet50_weights = 'IMAGENET1K_V2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Custom Tokenizer used for OCR Detection Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tokenizer for OCR Detection task\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file = 'C:/Users/ra78lof/occinference/byte-level-BPE.tokenizer.json')\n",
    "#feature_extractor = AutoFeatureExtractor.from_pretrained('microsoft/swin-base-batch4-window7-224-in22k')\n",
    "\n",
    "# Add PAD token to the vocabulary, otherwise it will throw an error\n",
    "tokenizer.add_special_tokens({'pad_token': \"pad_token\"})\n",
    "\n",
    "# Debug test for blank token, this token is required for CTC loss\n",
    "# tokenizer.decode(62)\n",
    "\n",
    "# Debug test for pad token, this token is required for padding sequences\n",
    "# print(tokenizer.pad_token_id)\n",
    "\n",
    "# Debug test for token length, this is required for the model building\n",
    "# print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CustomDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, excel_file, img_dir, tokenizer = tokenizer, feature_extractor = None, transform=None, max_target_length = 45):\n",
    "        self.data = pd.read_excel(excel_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.transform = transform\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data['ImageName'][idx]\n",
    "        text = self.data['Labels'][idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # The labels MUST be tokenized and padded\n",
    "        labels = self.tokenizer(text, padding = 'max_length', max_length = self.max_target_length).input_ids\n",
    "        \n",
    "\n",
    "        return image, torch.as_tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model architecture, this CNN-LSTM architecture includes the following part: A modified resnet18 with pretrained weights, some medium CNN layers and LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A modified ResNet architecture for Optical Character Recognition (OCR).\n",
    "\n",
    "    Attributes:\n",
    "        features (nn.Sequential): A sequential container of the original ResNet layers excluding avgpool and fc layers.\n",
    "        conv1 (nn.Conv2d): Convolution layer to adjust input channels to 1 (grayscale images).\n",
    "        post_resnet1 (nn.Conv2d): Convolution layer following the features layer.\n",
    "        bn1 (nn.BatchNorm2d): Batch normalization layer following post_resnet1.\n",
    "        relu1 (nn.ReLU): ReLU activation layer following bn1.\n",
    "        post_resnet2 (nn.Conv2d): Another convolution layer following relu1.\n",
    "        bn2 (nn.BatchNorm2d): Batch normalization layer following post_resnet2.\n",
    "        relu2 (nn.ReLU): ReLU activation layer following bn2.\n",
    "        post_resnet3 (nn.Conv2d): Another convolution layer following relu2.\n",
    "        bn3 (nn.BatchNorm2d): Batch normalization layer following post_resnet3.\n",
    "        relu3 (nn.ReLU): ReLU activation layer following bn3.\n",
    "        dwv (nn.Conv2d): Depthwise convolution layer for channel reduction following relu3.\n",
    "        lstm1 (nn.LSTM): LSTM layer following the depthwise convolution.\n",
    "        linear1 (nn.Linear): Fully connected layer to project LSTM output to class scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, original_resnet: nn.Module):\n",
    "        \"\"\"\n",
    "        Initializes the ModifiedResNet with an original_resnet model.\n",
    "\n",
    "        Args:\n",
    "            original_resnet (nn.Module): The original ResNet model.\n",
    "        \"\"\"\n",
    "        super(ModifiedResNet, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_resnet.children())[:-2]) # Remove avgpool and fc layers in the original resnet\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # Adjust input channels to 1, since the input images are grayscale\n",
    "        \n",
    "        self.post_resnet1 = nn.Conv2d(512, 512, kernel_size=(2, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(512) # Batch normalization after post_resnet1, important for training\n",
    "        self.relu1 = nn.ReLU(inplace=True) # ReLU activation after post_resnet1, import for training\n",
    "        \n",
    "        self.post_resnet2 = nn.Conv2d(512, 512, kernel_size=(3, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(512) # Batch normalization after post_resnet2, important for training\n",
    "        self.relu2 = nn.ReLU(inplace=True) # ReLU activation after post_resnet2, import for training\n",
    "        \n",
    "        self.post_resnet3 = nn.Conv2d(512, 512, kernel_size=(2, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(512) # Batch normalization after post_resnet3, important for training\n",
    "        self.relu3 = nn.ReLU(inplace=True) # ReLU activation after post_resnet3, import for training\n",
    "        \n",
    "        self.dwv = nn.Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=False) # Depthwise Convolution for channel reduction\n",
    "        self.lstm1 = nn.LSTM(bidirectional=True, num_layers=2, input_size=128, hidden_size=128, dropout=0)\n",
    "        self.linear1 = nn.Linear(256, 82) # Project first dimension of LSTM output to 82 (number of classes including the PAD token)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the ModifiedResNet.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output tensor.\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = self.post_resnet1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.post_resnet2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.post_resnet3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = self.dwv(x)\n",
    "        \n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.permute(0, 2, 3, 1).contiguous() # Change the order of the dimensions, this is required for the LSTM layer\n",
    "        x = x.view(batch_size, height * width, channels) # Reshape to (batch_size, sequence_length, input_dim)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.linear1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple debug test with a dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug test for the ModifiedResNet\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dummy_input = torch.randn(32, 1, 500, 1200).to(device)\n",
    "\n",
    "original_resnet = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "original_resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model= ModifiedResNet(original_resnet).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation for Train, valid and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms for the dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((500, 1200)),  # Resize images to the required dimensions\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training, Validation and Test data\n",
    "\n",
    "train_dataset = CustomDataset(excel_file='C:/Users/ra78lof/occinference/Train_data.xlsx',\n",
    "                             img_dir='C:/Users/ra78lof/occinference/Train_data/', tokenizer = tokenizer, transform=transform)\n",
    "\n",
    "valid_dataset = CustomDataset(excel_file='C:/Users/LMMISTA-WAP265/OcciGen/data/dom_project/Val_data.xlsx',\n",
    "                              img_dir='C:/Users/LMMISTA-WAP265/OcciGen/data/dom_project/Val_data/', tokenizer = tokenizer, transform=transform)\n",
    "\n",
    "test_dataset = CustomDataset(excel_file='C:/Users/ra78lof/occinference/Test_data.xlsx',\n",
    "                             img_dir='C:/Users/ra78lof/occinference/Test_data/', tokenizer = tokenizer, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataLoaders\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model, optimizer, scheduler and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, optimizer, scheduler and loss function\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "original_resnet = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "original_resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model= ModifiedResNet(original_resnet).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=1, eta_min=0.0001, last_epoch=-1, verbose=False)\n",
    "iters = len(train_loader)\n",
    "# The following scheduler can be used during validation\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, threshold=0.0001, min_lr=0.00001)\n",
    "# ...valid_loss += loss.item()\n",
    "#    scheduler.step(valid_loss)...\n",
    "\n",
    "# The CTC loss function is returning blank predictions for some reason\n",
    "# criterion = CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Wandb to track the Epochs\n",
    "# wandb.watch(model, log=\"all\")\n",
    "epoch = 200\n",
    "\n",
    "def training(model: torch.nn.Module, \n",
    "                     train_loader: DataLoader, \n",
    "                     optimizer: optim.Optimizer,\n",
    "                     scheduler: optim.lr_scheduler, \n",
    "                     criterion: nn.Module,\n",
    "                     device: torch.device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to train.\n",
    "    - optimizer: The optimizer to use.\n",
    "    - scheduler: The learning rate scheduler.\n",
    "    - criterion: The loss function.\n",
    "    - train_loader: The data loader for training data.\n",
    "    - device: The device to train on (In our case would be cuda).\n",
    "\n",
    "    Returns:\n",
    "    - The average training loss for the epoch.\n",
    "    \"\"\"\n",
    "     \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc='Train')\n",
    "    for batch_idx, (data, target) in pbar:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data) \n",
    "\n",
    "        loss = criterion(output.view(-1, output.size(2)), target.view(-1))  \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch + batch_idx / iters)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']   \n",
    "        pbar.set_postfix(train_loss = f'{epoch_train_loss:.4f}',\n",
    "                        lr = f'{current_lr:.6f})')\n",
    "                \n",
    "    # If the Scheduler like CosineAnnealing is used, then the scheduler.step() should be used after each epoch            \n",
    "    # scheduler.step()       \n",
    "\n",
    "    # Do not use print if the tqdm is used\n",
    "    # print(\"Time taken for epoch: \", end_time - start_time)\n",
    "    return epoch_train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validating(model: torch.nn.Module, \n",
    "               valid_loader: DataLoader, \n",
    "               criterion: nn.Module, \n",
    "               device: torch.device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to test.\n",
    "    - valid_loader: The data loader for validating data.\n",
    "    - criterion: The loss function.\n",
    "    - device: The device to validate on (e.g., 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - The average validating loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "\n",
    "    pbar = tqdm(enumerate(valid_loader), total=len(valid_loader), desc='Valid')\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in pbar:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "           \n",
    "            loss = criterion(output.view(-1, output.size(2)), target.view(-1))\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "            epoch_valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "            # If the Scheduler like ReduceLROnPlateau is used, then the scheduler.step() should be used after each epoch\n",
    "            # scheduler.step(valid_loss)\n",
    "\n",
    "            pbar.set_postfix(valid_loss = f'{epoch_valid_loss:.4f}')\n",
    "    return epoch_valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model: torch.nn.Module, \n",
    "         test_loader: DataLoader, \n",
    "         criterion: nn.Module, \n",
    "         device: torch.device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to test.\n",
    "    - test_loader: The data loader for testing data.\n",
    "    - criterion: The loss function.\n",
    "    - device: The device to test on (e.g., 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - The average validating loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load('C:/Users/ra78lof/occinference/ocr_model.pt'))\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Test')\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output.view(-1, output.size(2)), target.view(-1))\n",
    "            test_loss += loss.item()\n",
    "            epoch_test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "            pbar.set_postfix(test_loss = f'{epoch_test_loss:.4f}')\n",
    "    return epoch_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: torch.nn.Module, \n",
    "               filename: str, \n",
    "               is_best: bool = False):\n",
    "    \"\"\"\n",
    "    Save the model's state dict to a file.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    if is_best:\n",
    "        wandb.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the whole training, validating and test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model: torch.nn.Module, \n",
    "                 train_loader: DataLoader,\n",
    "                 valid_loader: DataLoader,\n",
    "                 test_loader: DataLoader,\n",
    "                 optimizer: torch.optim.Optimizer, \n",
    "                 scheduler: torch.optim.lr_scheduler,\n",
    "                 criterion: nn.Module,\n",
    "                 device: torch.device, \n",
    "                 num_epochs: int):\n",
    "    \"\"\"\n",
    "    Train the model for a specified number of epochs and log metrics to wandb.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to train.\n",
    "    - optimizer: The optimizer to use.\n",
    "    - scheduler: The learning rate scheduler.\n",
    "    - device: The device to train on (e.g., 'cuda').\n",
    "    - num_epochs: The number of epochs to train.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing the trained model and training history.\n",
    "    \"\"\"\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    # ema = EMA(model)\n",
    "    \n",
    "    # Test if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"cuda: {torch.cuda.get_device_name()}\\n\")\n",
    "     \n",
    "    start_time = time.time()\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_valid = -np.inf\n",
    "    best_epoch = -1\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    run = wandb.init(\n",
    "        project='OCR_Recognition',\n",
    "        config={k: v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
    "        anonymous=CFG.anonymous,\n",
    "        name=f\"dim-{CFG.image_size[0]}x{CFG.image_size[1]}|model-{CFG.backend_model}\",\n",
    "        #group=CFG.comment,\n",
    "        force = CFG.force,\n",
    "        notes = CFG.notes,\n",
    "        save_code = CFG.save_code\n",
    "    )\n",
    "    \n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "\n",
    "        train_loss = training(model, train_loader, optimizer, scheduler, criterion, device)\n",
    "        val_loss= validating(model, valid_loader, criterion, device)\n",
    "        test_loss = testing(model, test_loader, criterion, device)\n",
    "\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Test Loss'].append(test_loss)\n",
    "\n",
    "        # Log the metrics\n",
    "        wandb.log({\"Train Loss\": train_loss,\n",
    "                   \"Valid Loss\": val_loss,\n",
    "                   \"Test Loss\": test_loss,\n",
    "                   \"LR\":scheduler.get_last_lr()[0]})\n",
    "\n",
    "        # deep copy the model\n",
    "        if val_loss <= best_valid:\n",
    "            print(f\"Valid Loss Improved ({best_valid:0.4f} ---> {val_loss:0.4f})\")\n",
    "            best_valid = val_loss\n",
    "            run.summary[\"Best Valid\"]  = best_valid\n",
    "        \n",
    "        if test_loss <= best_test:\n",
    "            print(f\"Test Loss Improved ({best_test:0.4f} ---> {test_loss:0.4f})\")\n",
    "            best_test = test_loss\n",
    "            best_epoch = epoch\n",
    "            run.summary[\"Best Test\"] = best_test   \n",
    "            run.summary[\"Best Epoch\"] = best_epoch\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_epoch.pt\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            wandb.save(PATH)\n",
    "            print(f\"Model Saved\")\n",
    "\n",
    "        last_epoch_model = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch.pt\"\n",
    "        torch.save(last_epoch_model, PATH)\n",
    "        # wandb.log({\"Last Epoch Model\": wandb.Artifact(\"last_epoch_model\", type=\"model\", description=\"last_epoch_model\")})\n",
    "        # torch.save(model.state_dict(), PATH)\n",
    "        wandb.save(PATH)\n",
    "\n",
    "        print(); print()\n",
    "\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f'Training complete in {hours:.0f}h {minutes:.0f}m {seconds:.0f}s')\n",
    "    print(f\"Best Test: {best_test:.4f}\")\n",
    "\n",
    "    wandb.log({\"Training Time\": elapsed_time})\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is setted up, let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_resnet = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "original_resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model = ModifiedResNet(original_resnet).to(device)\n",
    "\n",
    "model, history = run_training(model, train_loader, valid_loader, test_loader, optimizer, scheduler, criterion, device, epoch)   \n",
    "# A finetuned model is saved in the current directory   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate the test dataset to get the predictions\n",
    "label_list = []\n",
    "pred_list = []\n",
    "\n",
    "# Load our trained model\n",
    "model.load_state_dict(torch.load('C:/Users/ra78lof/HardOCR/ocr_model_10.25_finetune_4.pt'))\n",
    "\n",
    "for _, (data, target) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = model(data)\n",
    "        # Get the index of the class with the highest probability score\n",
    "        pred = output.softmax(dim=2)\n",
    "        pred = torch.argmax(pred, dim=2)\n",
    "        label_list += tokenizer.batch_decode(target, skip_special_tokens=True)\n",
    "        pred_list += tokenizer.batch_decode(pred, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode one batch of the test dataset to get the predictions\n",
    "# This is just for debugging purposes  \n",
    "data, target = next(iter(test_loader))\n",
    "data = data.to(device)\n",
    "target = target.to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "pred = output.softmax(dim=2)\n",
    "pred = torch.argmax(pred, dim=2)\n",
    "\n",
    "# Decode the predictions and labels\n",
    "label = tokenizer.batch_decode(target, skip_special_tokens=True)\n",
    "pred = tokenizer.batch_decode(pred, skip_special_tokens=True)\n",
    "\n",
    "# Print the predictions and labels\n",
    "print(f'Label: {label}')\n",
    "print(f'Prediction: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the predictions in an excel file\n",
    "\n",
    "pd.DataFrame({'label': label_list, 'pred': pred_list}).to_excel('C:/Users/ra78lof/occinference/ocr_predictions_10.22_10.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
